{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VChWkdFGQl82"
      },
      "outputs": [],
      "source": [
        "########code for transfor learning using resnet50\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.models import load_model\n",
        "import numpy as np\n",
        "\n",
        "# Path to the dataset directory\n",
        "train_dataset_path = '/content/gdrive/My Drive/race classification/Dataset/train'\n",
        "test_dataset_path = '/content/gdrive/My Drive/race classification/Dataset/test'\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)\n",
        "# Load the dataset\n",
        "train_dataset = tf.keras.utils.image_dataset_from_directory(\n",
        "    train_dataset_path,\n",
        "    labels='inferred',  # Automatically infer labels from folder names\n",
        "    label_mode='int',   # Return integer labels (can also be 'categorical' or 'binary')\n",
        "    image_size=(224, 224),  # Resize all images to this size\n",
        "    batch_size=4,      # Number of images in each batch\n",
        "    shuffle=True,       # Shuffle the data\n",
        "    seed=42,            # Seed for reproducibility\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "# Load the validation dataset\n",
        "test_dataset = tf.keras.utils.image_dataset_from_directory(\n",
        "    test_dataset_path,\n",
        "    labels='inferred',\n",
        "    label_mode='int',\n",
        "    image_size=(224, 224),\n",
        "    batch_size=1,\n",
        "    shuffle=False,\n",
        "\n",
        ")\n",
        "\n",
        "from tensorflow.keras.applications import ResNet50, VGG16\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Load pre-trained ResNet50 model without the top layers (classification layers)\n",
        "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "# Freeze all layers except the last few\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Unfreeze the last few layers (e.g., the last 4 layers)\n",
        "for layer in base_model.layers[-8:]:\n",
        "    layer.trainable = True\n",
        "\n",
        "# Add custom layers\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)  # Global average pooling to reduce the dimensionality\n",
        "x = Dense(1024, activation='relu')(x)  # Fully connected layer\n",
        "predictions = Dense(2, activation='softmax')(x)  # Output layer (Asian, non-Asian)\n",
        "\n",
        "# Define the model\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
        "              loss='sparse_categorical_crossentropy',  # Use 'binary_crossentropy' if using two output neurons\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "checkpoint = ModelCheckpoint(\n",
        "    '/content/gdrive/My Drive/race classification/best_model_resnet-V2[last 8 layers].keras',  # File path where the model will be saved\n",
        "    monitor='val_accuracy',  # Metric to monitor\n",
        "    save_best_only=True,  # Save only the best model (with the lowest validation loss)\n",
        "    mode='max',  # Mode is 'min' for validation loss since lower is better\n",
        "    verbose=1  # Print messages when saving the model\n",
        ")\n",
        "# Train the model\n",
        "model.fit(\n",
        "    train_dataset,\n",
        "    validation_data=test_dataset,\n",
        "    callbacks=[checkpoint],  # Include the ModelCheckpoint callback\n",
        "    epochs=300\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "resnet_model=load_model('/content/gdrive/My Drive/race classification/best_model_resnet-V2[last 8 layers].keras')\n",
        "\n",
        "resnet_pred = resnet_model.predict(test_dataset, verbose=1)\n",
        "\n",
        "final_predictions = np.argmax(resnet_pred, axis=1)\n",
        "true_labels = []\n",
        "for _, labels in test_dataset:\n",
        "    true_labels.extend(labels.numpy())\n",
        "true_labels = np.array(true_labels)\n",
        "\n",
        "accuracy = accuracy_score(true_labels, final_predictions)\n",
        "print(f\"\\nâœ… Ensemble Accuracy: {accuracy * 100:.2f}%\")\n",
        "\n",
        "print(\"\\nðŸ“‹ Classification Report:\")\n",
        "print(classification_report(true_labels, final_predictions, target_names=test_dataset.class_names))\n",
        "\n",
        "print(\"\\nðŸ“Š Confusion Matrix:\")\n",
        "print(confusion_matrix(true_labels, final_predictions))\n",
        "\n",
        "\n",
        "# Model summary\n",
        "vgg_model.summary()"
      ],
      "metadata": {
        "id": "5DtkjzdaQwbu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "############  FaceNet embeddings, MTCNN,  Logistic Regression\n",
        "\n",
        "\n",
        "\n",
        "from skimage.feature import local_binary_pattern\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.svm import SVC\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.models import load_model\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "import os\n",
        "import cv2\n",
        "import torch\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from facenet_pytorch import InceptionResnetV1, MTCNN\n",
        "\n",
        "# Path to the dataset directory\n",
        "train_dataset_path = '/content/gdrive/My Drive/race classification/Dataset/train'\n",
        "test_dataset_path = '/content/gdrive/My Drive/race classification/Dataset/test'\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)\n",
        "# Load the dataset\n",
        "train_dataset = tf.keras.utils.image_dataset_from_directory(\n",
        "    train_dataset_path,\n",
        "    labels='inferred',  # Automatically infer labels from folder names\n",
        "    label_mode='int',   # Return integer labels (can also be 'categorical' or 'binary')\n",
        "    image_size=(224, 224),  # Resize all images to this size\n",
        "    batch_size=4,      # Number of images in each batch\n",
        "    shuffle=True,       # Shuffle the data\n",
        "    seed=42,            # Seed for reproducibility\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "# Load the validation dataset\n",
        "test_dataset = tf.keras.utils.image_dataset_from_directory(\n",
        "    test_dataset_path,\n",
        "    labels='inferred',\n",
        "    label_mode='int',\n",
        "    image_size=(224, 224),\n",
        "    batch_size=1,\n",
        "    shuffle=False,\n",
        "\n",
        ")\n",
        "# Load FaceNet and MTCNN\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "facenet = InceptionResnetV1(pretrained='vggface2').eval().to(device)\n",
        "mtcnn = MTCNN(image_size=160, device=device)\n",
        "\n",
        "# Function to extract embeddings and labels from tf.data.Dataset\n",
        "def extract_embeddings(dataset):\n",
        "    embeddings, labels = [], []\n",
        "    for batch_images, batch_labels in dataset:\n",
        "        for img_tensor, label in zip(batch_images, batch_labels):\n",
        "            img = tf.image.resize(img_tensor, (160, 160)).numpy().astype(\"uint8\")\n",
        "            face = mtcnn(img)\n",
        "            if face is not None:\n",
        "                with torch.no_grad():\n",
        "                    emb = facenet(face.unsqueeze(0).to(device)).cpu().numpy().flatten()\n",
        "                    embeddings.append(emb)\n",
        "                    labels.append(label.numpy())\n",
        "    return np.array(embeddings), np.array(labels)\n",
        "# === Extract embeddings ===\n",
        "print(\"Extracting embeddings from training dataset...\")\n",
        "X_train, y_train = extract_embeddings(train_dataset)\n",
        "\n",
        "print(\"Extracting embeddings from test dataset...\")\n",
        "X_test, y_test = extract_embeddings(test_dataset)\n",
        "\n",
        "# === Train logistic regression ===\n",
        "clf = LogisticRegression(max_iter=1000)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# === Evaluate ===\n",
        "y_pred = clf.predict(X_test)\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))"
      ],
      "metadata": {
        "id": "sRPitXVGSDut"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "############  FaceNet embeddings, MTCNN,  MLP\n",
        "\n",
        "\n",
        "from skimage.feature import local_binary_pattern\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.svm import SVC\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.layers import BatchNormalization, Dense, Dropout\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import numpy as np\n",
        "\n",
        "import os\n",
        "import cv2\n",
        "import torch\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from facenet_pytorch import InceptionResnetV1, MTCNN\n",
        "from tensorflow.keras.layers import Input, Dense\n",
        "\n",
        "# Path to the dataset directory\n",
        "train_dataset_path = '/content/gdrive/My Drive/race classification/Dataset/train'\n",
        "test_dataset_path = '/content/gdrive/My Drive/race classification/Dataset/test'\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)\n",
        "\n",
        "# Load the dataset\n",
        "train_dataset = tf.keras.utils.image_dataset_from_directory(\n",
        "    train_dataset_path,\n",
        "    labels='inferred',\n",
        "    label_mode='int',\n",
        "    image_size=(224, 224),\n",
        "    batch_size=4,\n",
        "    shuffle=True,\n",
        "    seed=42,\n",
        ")\n",
        "\n",
        "# Load the validation dataset\n",
        "test_dataset = tf.keras.utils.image_dataset_from_directory(\n",
        "    test_dataset_path,\n",
        "    labels='inferred',\n",
        "    label_mode='int',\n",
        "    image_size=(224, 224),\n",
        "    batch_size=1,\n",
        "    shuffle=False,\n",
        ")\n",
        "\n",
        "# Load FaceNet and MTCNN\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "facenet = InceptionResnetV1(pretrained='vggface2').eval().to(device)\n",
        "mtcnn = MTCNN(image_size=160, device=device)\n",
        "\n",
        "# Function to extract embeddings and labels from tf.data.Dataset\n",
        "def extract_embeddings(dataset):\n",
        "    embeddings, labels = [], []\n",
        "    for batch_images, batch_labels in dataset:\n",
        "        for img_tensor, label in zip(batch_images, batch_labels):\n",
        "            img = tf.image.resize(img_tensor, (160, 160)).numpy().astype(\"uint8\")\n",
        "            face = mtcnn(img)\n",
        "            if face is not None:\n",
        "                with torch.no_grad():\n",
        "                    emb = facenet(face.unsqueeze(0).to(device)).cpu().numpy().flatten()\n",
        "                    embeddings.append(emb)\n",
        "                    labels.append(label.numpy())\n",
        "    return np.array(embeddings), np.array(labels)\n",
        "\n",
        "# === Extract embeddings ===\n",
        "print(\"Extracting embeddings from training dataset...\")\n",
        "X_train, y_train = extract_embeddings(train_dataset)\n",
        "\n",
        "print(\"Extracting embeddings from test dataset...\")\n",
        "X_test, y_test = extract_embeddings(test_dataset)\n",
        "\n",
        "# Convert labels to categorical\n",
        "num_classes = len(np.unique(y_train))\n",
        "y_train_cat = to_categorical(y_train, num_classes)\n",
        "y_test_cat = to_categorical(y_test, num_classes)\n",
        "\n",
        "# === Define MLP model ===\n",
        "model = Sequential([\n",
        "    Input(shape=(X_train.shape[1],)),  # Proper input layer\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer=Adam(learning_rate=1e-3),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# === Train MLP ===\n",
        "model.fit(X_train, y_train_cat, epochs=20, batch_size=32, validation_split=0.1)\n",
        "\n",
        "# === Evaluate on test data ===\n",
        "test_loss, test_acc = model.evaluate(X_test, y_test_cat)\n",
        "print(f\"Test Accuracy: {test_acc:.4f}\")\n",
        "\n",
        "# === Predict and classification report ===\n",
        "y_pred_probs = model.predict(X_test)\n",
        "y_pred = np.argmax(y_pred_probs, axis=1)\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))"
      ],
      "metadata": {
        "id": "QkztGHtbSSG3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}